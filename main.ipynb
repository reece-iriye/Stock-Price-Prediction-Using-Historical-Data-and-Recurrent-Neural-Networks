{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Stock Price Prediction Using Historical Data and Recurrent Neural Networks (RNNs)** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Author:** Reece Iriye\n",
    "### **Course:** MATH 4377 (Math of Machine Learning)\n",
    "### **Section:** Fall 2022, TTh 12:30-1:50PM, 001-LEC\n",
    "### **Department:** Mathematics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Description**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project studies the usage of historical data and recurrent neural network to predict a stock price or an index. I will choose to use regression to predict a stock price or an index, instead of classification to predict whether or not there exists an overall upward or downward trend."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Generation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to http://finance.yahoo.com\n",
    "2. Search one (or several, depending on the need for your model) of the stocks from a company (apple, amazon, microsoft, etc.) or one or several stock indices (S&P 500, Dow 30, Nasdaq, Russell 2000, Crude Oil, etc.)\n",
    "3. Once the stock or index’s quote page is shown, click the “Historic Data” tab and change “the time period” as needed. Note normally we prefer more data for a neural network.\n",
    "4. Click “Apply” and then click “download” below the “Apply” button and a CSV data will be generated and downloaded to your computer.\n",
    "\n",
    "\n",
    "*Note*: I will need to pick a time period and decide how many data points to produce. I will need to rearrange the data into time series by lagging the data to obtain percentage returns instead of raw closing price data. I will also need to split my data into a training set and a testing set thus the validation can be performed. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Recurrent Neural Network (RNN)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to setup a RNN model and use the obtained data to predict stock prices. I will consider the following questions when you setup the RNN:\n",
    "\n",
    "\n",
    "1. What's the overall dimension of the RNN?\n",
    "2. What is the number of time steps for returns? In predicting n-day returns, what am I specifying as n?\n",
    "3. How many neurons are in the hidden layer?\n",
    "4. Did I use the LSTM, if so what are the related parameters?\n",
    "5. What is my choice of activation function? Why?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Research Objective**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this project, I will demonstrate:\n",
    "1. Cleaning and rearranging data in the form that a neural network can be applied on.\n",
    "2. Setting up a RNN model that is working.\n",
    "3. Further tuning the model by modifying model parameters to finalize an optimized model.\n",
    "4. Getting *creative* based on accumulated knowledge and skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split  # for splitting dataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential   # the RNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Implementation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Necessary Data**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will predict Target Corporation's (NYSE: TGT) returns in 2019 using historical data from 01/02/2000 - 12/31/2018. Using Bloomberg Terminal which is downloaded on the computers in SMU's business library, I will scrape data using the `BDH` Excel function connected with Bloomberg and download the data to a CSV file, so I can store closing price data into a DataFrame using Pandas. I used Bloomberg Terminal instead of Yahoo Finance, because Yahoo did not allow me to download the closing price data from every single one of my indices and equities that I wanted to use for the project.\n",
    "\n",
    "\n",
    "\n",
    "Additionally, I'm using the training time period from 2000-2018, because that time period captures a wide array of market phases that the United States has gone through, with some periods of growth but also with the Stock Market Crash of 2008. I'm using 2019 as a testing year, because it may be somewhat predictable especially with the market trends happening a couple years before it that I will train the RNN on. I did not want to test it on 2020, because my model likely would not have factored in the COVID crash that occurred based solely on historical data of various indices and equities.\n",
    "\n",
    "\n",
    "\n",
    "Predictors for TGT that I'll include:\n",
    "- Benchmark Indices:\n",
    "    - SPX Index\n",
    "        - The SPX Index, also known as the S&P 500, is the basic index that generally describes the overall state of the market based on the top 500 performing companies.\n",
    "    - RUI Index (Russell 1000)\n",
    "        - The Russell 1000 represents the top 1000 companies by market capitalization in the United States.\n",
    "    - FED5YEAR Index\n",
    "        - The FED5Year is the yield of a US Treasury note that pays out in 5 years. \n",
    "    - VIX Index\n",
    "        - VIX is the volatility index that measures the volatility of the S&P 500 options and shows how volatile the stock market can be at certain times.\n",
    "    - DXY Curncy\n",
    "        - DXY measures the price of the US Dollar in comparison to other currencies.\n",
    "- Competitor Indices:\n",
    "    - Costco Wholesale Corporation (NASDAQ: COST)\n",
    "    - Walmart Inc (NYSE: WMT)\n",
    "    - Macy's Inc (NYSE: M)\n",
    "- Industry-Specific Metric:\n",
    "    - SPSIRE (S&P Retail Select Industry Index)\n",
    "        - SPSIRE measures the performance of the retail sector in the stock market. \n",
    "- Historical TGT Data:\n",
    "    - The Performance of previous TGT data will help us gage how exactly Target stock is performing and what its general trends are. \n",
    "\n",
    "\n",
    "I am using all these factors, because I wanted to use a variety of predictors that represent the overall state of the market, the performance of the US dollar, the performance of competitors who are similar in nature, the retail sector's performance, and the TGT historical data itself. Using only a couple of these factors I believe would have limited myself, and I wanted to branch out using multiple predictors to hopefully build an accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SPX</th>\n",
       "      <th>RUI</th>\n",
       "      <th>FED5YEAR</th>\n",
       "      <th>VIX</th>\n",
       "      <th>DXY</th>\n",
       "      <th>COST</th>\n",
       "      <th>WMT</th>\n",
       "      <th>M</th>\n",
       "      <th>SPSIRE</th>\n",
       "      <th>TGT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/00</td>\n",
       "      <td>1469.25</td>\n",
       "      <td>3055.86</td>\n",
       "      <td>2.7701</td>\n",
       "      <td>24.64</td>\n",
       "      <td>101.87</td>\n",
       "      <td>45.625</td>\n",
       "      <td>69.1250</td>\n",
       "      <td>25.2813</td>\n",
       "      <td>1041.97</td>\n",
       "      <td>36.7188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/3/00</td>\n",
       "      <td>1455.22</td>\n",
       "      <td>3029.45</td>\n",
       "      <td>2.7473</td>\n",
       "      <td>24.21</td>\n",
       "      <td>100.22</td>\n",
       "      <td>44.500</td>\n",
       "      <td>66.8125</td>\n",
       "      <td>25.1875</td>\n",
       "      <td>1016.40</td>\n",
       "      <td>36.0313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/4/00</td>\n",
       "      <td>1399.42</td>\n",
       "      <td>2909.98</td>\n",
       "      <td>2.8377</td>\n",
       "      <td>27.01</td>\n",
       "      <td>100.41</td>\n",
       "      <td>42.063</td>\n",
       "      <td>64.3125</td>\n",
       "      <td>24.4688</td>\n",
       "      <td>989.24</td>\n",
       "      <td>34.4688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/5/00</td>\n",
       "      <td>1402.11</td>\n",
       "      <td>2917.77</td>\n",
       "      <td>2.8245</td>\n",
       "      <td>26.41</td>\n",
       "      <td>100.38</td>\n",
       "      <td>42.781</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>24.9375</td>\n",
       "      <td>989.65</td>\n",
       "      <td>33.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/6/00</td>\n",
       "      <td>1403.45</td>\n",
       "      <td>2898.75</td>\n",
       "      <td>2.7696</td>\n",
       "      <td>25.73</td>\n",
       "      <td>100.48</td>\n",
       "      <td>43.641</td>\n",
       "      <td>63.6875</td>\n",
       "      <td>24.7188</td>\n",
       "      <td>990.10</td>\n",
       "      <td>32.0938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/9/00</td>\n",
       "      <td>1441.47</td>\n",
       "      <td>2998.01</td>\n",
       "      <td>2.6760</td>\n",
       "      <td>21.72</td>\n",
       "      <td>100.72</td>\n",
       "      <td>46.531</td>\n",
       "      <td>68.5000</td>\n",
       "      <td>25.4063</td>\n",
       "      <td>1010.94</td>\n",
       "      <td>33.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/10/00</td>\n",
       "      <td>1457.60</td>\n",
       "      <td>3041.51</td>\n",
       "      <td>2.5936</td>\n",
       "      <td>21.71</td>\n",
       "      <td>100.99</td>\n",
       "      <td>47.500</td>\n",
       "      <td>67.2500</td>\n",
       "      <td>26.1875</td>\n",
       "      <td>1019.65</td>\n",
       "      <td>33.0938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/11/00</td>\n",
       "      <td>1438.56</td>\n",
       "      <td>2996.16</td>\n",
       "      <td>2.7436</td>\n",
       "      <td>22.50</td>\n",
       "      <td>100.56</td>\n",
       "      <td>45.813</td>\n",
       "      <td>66.2500</td>\n",
       "      <td>25.3438</td>\n",
       "      <td>1005.29</td>\n",
       "      <td>34.0938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/12/00</td>\n",
       "      <td>1432.25</td>\n",
       "      <td>2985.80</td>\n",
       "      <td>2.8011</td>\n",
       "      <td>22.84</td>\n",
       "      <td>100.62</td>\n",
       "      <td>45.750</td>\n",
       "      <td>65.0625</td>\n",
       "      <td>25.2813</td>\n",
       "      <td>992.22</td>\n",
       "      <td>33.7188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/13/00</td>\n",
       "      <td>1449.68</td>\n",
       "      <td>3031.35</td>\n",
       "      <td>2.7769</td>\n",
       "      <td>21.71</td>\n",
       "      <td>101.00</td>\n",
       "      <td>47.469</td>\n",
       "      <td>65.1250</td>\n",
       "      <td>25.6250</td>\n",
       "      <td>996.90</td>\n",
       "      <td>34.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date      SPX      RUI  FED5YEAR    VIX     DXY    COST      WMT  \\\n",
       "0   1/2/00  1469.25  3055.86    2.7701  24.64  101.87  45.625  69.1250   \n",
       "1   1/3/00  1455.22  3029.45    2.7473  24.21  100.22  44.500  66.8125   \n",
       "2   1/4/00  1399.42  2909.98    2.8377  27.01  100.41  42.063  64.3125   \n",
       "3   1/5/00  1402.11  2917.77    2.8245  26.41  100.38  42.781  63.0000   \n",
       "4   1/6/00  1403.45  2898.75    2.7696  25.73  100.48  43.641  63.6875   \n",
       "5   1/9/00  1441.47  2998.01    2.6760  21.72  100.72  46.531  68.5000   \n",
       "6  1/10/00  1457.60  3041.51    2.5936  21.71  100.99  47.500  67.2500   \n",
       "7  1/11/00  1438.56  2996.16    2.7436  22.50  100.56  45.813  66.2500   \n",
       "8  1/12/00  1432.25  2985.80    2.8011  22.84  100.62  45.750  65.0625   \n",
       "9  1/13/00  1449.68  3031.35    2.7769  21.71  101.00  47.469  65.1250   \n",
       "\n",
       "         M   SPSIRE      TGT  \n",
       "0  25.2813  1041.97  36.7188  \n",
       "1  25.1875  1016.40  36.0313  \n",
       "2  24.4688   989.24  34.4688  \n",
       "3  24.9375   989.65  33.6875  \n",
       "4  24.7188   990.10  32.0938  \n",
       "5  25.4063  1010.94  33.7500  \n",
       "6  26.1875  1019.65  33.0938  \n",
       "7  25.3438  1005.29  34.0938  \n",
       "8  25.2813   992.22  33.7188  \n",
       "9  25.6250   996.90  34.5000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pxlast = pd.read_csv(\"data/full_data.csv\")\n",
    "df_pxlast.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the closing price data for my predictors has been imported successfully. Now let's do the same for my testing data solutions of TGT closing prices to check whether or not that has been imported successfully as well"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Returns Data Using Lags of Closing Price Data**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data has been imported successfully into Pandas Dataframes. Now,  transform all the data into percentage returns data, because percentage returns have a mean-reverting characteristic that represents the normal distribution. We want a distribution like this, because it makes predictions more accurately in relation to its actual shape, instead of general closing price data which has a more $\\chi^2$ shape associated with it. \n",
    "\n",
    "\n",
    "\n",
    "Also, change the dates to datetime types in the Pandas DataFrame while we're already observing other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns = pd.DataFrame()\n",
    "for index, colname in enumerate(df_pxlast):\n",
    "    if colname == \"Date\":\n",
    "        df_returns[colname] = pd.to_datetime(df_pxlast[colname][1:])\n",
    "    else:\n",
    "        df_returns[colname + \" Returns\"] = df_pxlast[colname].pct_change(1)\n",
    "df_returns.set_index(df_returns[\"Date\"], inplace=True)\n",
    "df_returns.drop(\"Date\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPX Returns</th>\n",
       "      <th>RUI Returns</th>\n",
       "      <th>FED5YEAR Returns</th>\n",
       "      <th>VIX Returns</th>\n",
       "      <th>DXY Returns</th>\n",
       "      <th>COST Returns</th>\n",
       "      <th>WMT Returns</th>\n",
       "      <th>M Returns</th>\n",
       "      <th>SPSIRE Returns</th>\n",
       "      <th>TGT Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>-0.009549</td>\n",
       "      <td>-0.008642</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>-0.017451</td>\n",
       "      <td>-0.016197</td>\n",
       "      <td>-0.024658</td>\n",
       "      <td>-0.033454</td>\n",
       "      <td>-0.003710</td>\n",
       "      <td>-0.024540</td>\n",
       "      <td>-0.018723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>-0.038345</td>\n",
       "      <td>-0.039436</td>\n",
       "      <td>0.032905</td>\n",
       "      <td>0.115655</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>-0.054764</td>\n",
       "      <td>-0.037418</td>\n",
       "      <td>-0.028534</td>\n",
       "      <td>-0.026722</td>\n",
       "      <td>-0.043365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>-0.004652</td>\n",
       "      <td>-0.022214</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.017070</td>\n",
       "      <td>-0.020408</td>\n",
       "      <td>0.019155</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>-0.022667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>0.000956</td>\n",
       "      <td>-0.006519</td>\n",
       "      <td>-0.019437</td>\n",
       "      <td>-0.025748</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.020102</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>-0.008770</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>-0.047308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-09</th>\n",
       "      <td>0.027090</td>\n",
       "      <td>0.034242</td>\n",
       "      <td>-0.033795</td>\n",
       "      <td>-0.155849</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.066222</td>\n",
       "      <td>0.075564</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>0.021048</td>\n",
       "      <td>0.051605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SPX Returns  RUI Returns  FED5YEAR Returns  VIX Returns  \\\n",
       "Date                                                                  \n",
       "2000-01-03    -0.009549    -0.008642         -0.008231    -0.017451   \n",
       "2000-01-04    -0.038345    -0.039436          0.032905     0.115655   \n",
       "2000-01-05     0.001922     0.002677         -0.004652    -0.022214   \n",
       "2000-01-06     0.000956    -0.006519         -0.019437    -0.025748   \n",
       "2000-01-09     0.027090     0.034242         -0.033795    -0.155849   \n",
       "\n",
       "            DXY Returns  COST Returns  WMT Returns  M Returns  SPSIRE Returns  \\\n",
       "Date                                                                            \n",
       "2000-01-03    -0.016197     -0.024658    -0.033454  -0.003710       -0.024540   \n",
       "2000-01-04     0.001896     -0.054764    -0.037418  -0.028534       -0.026722   \n",
       "2000-01-05    -0.000299      0.017070    -0.020408   0.019155        0.000414   \n",
       "2000-01-06     0.000996      0.020102     0.010913  -0.008770        0.000455   \n",
       "2000-01-09     0.002389      0.066222     0.075564   0.027813        0.021048   \n",
       "\n",
       "            TGT Returns  \n",
       "Date                     \n",
       "2000-01-03    -0.018723  \n",
       "2000-01-04    -0.043365  \n",
       "2000-01-05    -0.022667  \n",
       "2000-01-06    -0.047308  \n",
       "2000-01-09     0.051605  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_returns.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I specifically chose to use 1-day returns, because it's a decent gage on daily market activity and may work well when testing the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Split the Data into a Training Set and a Testing Set**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the data that I need categorized correctly, I will split the data into training and testing sets to ensure that we can apply the Recurrent Neural Network correctly. Based on the Time Series nature of the RNN, and based on my data and the custom dates that I want to use, I will not need to invoke the `train_test_split()` module from `scikit-learn`. Instead, I will create a new column in df_returns to indicate whether or not I will train the data on its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPX Returns</th>\n",
       "      <th>RUI Returns</th>\n",
       "      <th>FED5YEAR Returns</th>\n",
       "      <th>VIX Returns</th>\n",
       "      <th>DXY Returns</th>\n",
       "      <th>COST Returns</th>\n",
       "      <th>WMT Returns</th>\n",
       "      <th>M Returns</th>\n",
       "      <th>SPSIRE Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>0.049594</td>\n",
       "      <td>0.049689</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>-0.156917</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.045476</td>\n",
       "      <td>0.053484</td>\n",
       "      <td>0.070337</td>\n",
       "      <td>0.058489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>-0.014798</td>\n",
       "      <td>-0.005863</td>\n",
       "      <td>0.012334</td>\n",
       "      <td>0.013052</td>\n",
       "      <td>-0.002987</td>\n",
       "      <td>-0.002474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-30</th>\n",
       "      <td>-0.001242</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>-0.054072</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>0.004232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>-0.017540</td>\n",
       "      <td>-0.103035</td>\n",
       "      <td>-0.002375</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>-0.007995</td>\n",
       "      <td>0.006084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SPX Returns  RUI Returns  FED5YEAR Returns  VIX Returns  \\\n",
       "Date                                                                  \n",
       "2018-12-25     0.000000     0.000000          0.000000     0.000000   \n",
       "2018-12-26     0.049594     0.049689          0.002082    -0.156917   \n",
       "2018-12-27     0.008563     0.008387         -0.015526    -0.014798   \n",
       "2018-12-30    -0.001242    -0.000809          0.000444    -0.054072   \n",
       "2018-12-31     0.008492     0.008830         -0.017540    -0.103035   \n",
       "\n",
       "            DXY Returns  COST Returns  WMT Returns  M Returns  SPSIRE Returns  \n",
       "Date                                                                           \n",
       "2018-12-25     0.000290      0.000000     0.000000   0.000000        0.000000  \n",
       "2018-12-26     0.004856      0.045476     0.053484   0.070337        0.058489  \n",
       "2018-12-27    -0.005863      0.012334     0.013052  -0.002987       -0.002474  \n",
       "2018-12-30    -0.000819      0.004774     0.005896  -0.000666        0.004232  \n",
       "2018-12-31    -0.002375      0.008266     0.011071  -0.007995        0.006084  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_returns.loc[\"2000-01-03\":\"2018-12-31\", \"SPX Returns\":\"SPSIRE Returns\"]\n",
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test is (261, 9)\n"
     ]
    }
   ],
   "source": [
    "X_test = df_returns.loc[\"2019-01-01\":\"2019-12-31\", \"SPX Returns\":\"SPSIRE Returns\"]\n",
    "print(f\"Shape of X_test is {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2018-12-25    0.000000\n",
       "2018-12-26    0.057839\n",
       "2018-12-27   -0.006143\n",
       "2018-12-30    0.003863\n",
       "2018-12-31    0.017395\n",
       "Name: TGT Returns, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_returns.loc[\"2000-01-03\":\"2018-12-31\", \"TGT Returns\"]\n",
    "y_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_test is (261,)\n"
     ]
    }
   ],
   "source": [
    "y_test = df_returns.loc[\"2019-01-01\":\"2019-12-31\", \"TGT Returns\"]\n",
    "print(f\"Shape of y_test is {y_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Convert Training Data to LSTM Format**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now be transforming our `X_train` and `X_test` variables into numpy arrays so I can put them into Long Short-Term Memory (LSTM) format. The reason I need to make this change is because the model will only take in my data if it is in that specific format. My training and testing set for X will need to be reshaped using the `.reshape()` function from numpy, which will need to indicate batch size, time steps, and the number of features in our entire model.\n",
    "\n",
    "\n",
    "\n",
    "To further describe LSTM format, it essentially is an architecture employed in various RNNs because it is able to capture long-term dependencies in the data. This allows for the model to retain important information for longer periods of time, which I believe is crucial in a task like predicting stocks, because it requires remembering previous events to predict future events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is (4956, 9)\n",
      "The shape of X_test is (261, 9)\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrames to numpy arrays\n",
    "X_train_2D = X_train.values\n",
    "X_test_2D  = X_test.values\n",
    "\n",
    "# Obtain number of timesteps and feature count based on shape of DataFrame\n",
    "timesteps_train, num_features_train = X_train.shape\n",
    "timesteps_test, num_features_test   = X_test.shape\n",
    "\n",
    "print(f\"The shape of X_train is {X_train.shape}\\nThe shape of X_test is {X_test.shape}\")\n",
    "\n",
    "# Reshape the 2D array into a 3D array\n",
    "X_train_3D = np.reshape(X_train_2D, (1, timesteps_train, num_features_train))\n",
    "X_test_3D  = np.reshape(X_test_2D, (1, timesteps_test, num_features_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time around, I will predict it using only a batch_size of 1 and timesteps_train and timesteps_test as the exact number of dates in each X dataset. This batch size may lead to problems with my model because it does not check up on the values again and is almost as if we don't incorporate LSTM in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44725e87ea676ad54a1d04bd571a955ef3e1f81ad317abec2d67776713178d01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
